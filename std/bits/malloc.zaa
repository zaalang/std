//
// malloc
//

import std.stdio;
import std.stdlib;
import std.atomic.spinlock;

struct mem_result
{
  u32 errno;
  usize size;
  void mut *addr;

  mem_result() = default;
  mem_result(mem_result&) = default;
  ~mem_result() = default;
}

extern fn mem_alloc(usize size) -> mem_result;
extern fn mem_free(void *addr, usize size) -> void;

struct heap
{
  const KLASSES = [
    1, 2, 3, 4, 5, 6, 7, 8,
    9, 10, 12, 15,
    18, 20, 25, 31,
    36, 42, 50, 63,
    72, 84, 102, 127,
    146, 170, 204, 255,
    292, 340, 409, 511,
    584, 682, 818, 1023,
    1169, 1364, 1637, 2047,
    2340, 2730, 3276, 4095,
    4680, 5460, 6552, 8191,
  ];

  const PAGE_SIZE = 4096;

  const SECRET = 0xdecdbead;

  struct header
  {
    uintptr secret;
  }

  struct prefix
  {
    region mut *region;
  }

  struct entry : pub prefix
  {
    entry mut *next;
  }

  struct region
  {
    usize size;
    void mut *addr;

    usize klass;
    entry mut *firstfree;

    region mut *next;
    region mut *prev;

    u8[16] pad;

    region() = default;
    ~region() = default;
  }

  region mut *filled;
  region mut *[48] active;
  entry mut *[48] pending;
  region mut *firstfree;

  std::spin_lock lock;

  fn size_of_klass(usize i) -> usize
  {
    return KLASSES[i] << 4;
  }

  fn size_to_klass(usize n) -> usize
  {
    n = (n + sizeof<prefix> - 1) >> 4;

    if (n < 10)
      return n;

    if (n > 8190)
      return 63;

    n += 1;

    var i = cast<usize>(60 - __clz(n))*4 + 8;

    if (n > KLASSES[i+1])
      i += 2;

    if (n > KLASSES[i])
      i += 1;

    return i;
  }

  fn enqueue(region mut * mut &head, region mut *region) -> void
  {
    if (head)
    {
      region.prev = head.prev;
      region.next = head;

      region.prev.next = region;
      region.next.prev = region;
    }
    else
    {
      region.prev = region.next = region;

      head = region;
    }
  }

  fn dequeue(region mut * mut &head, region mut *region) -> void
  {
    if (region.next != region)
    {
      region.prev.next = region.next;
      region.next.prev = region.prev;

      if (head == region)
        head = region.next;
    }
    else
    {
      head = null;
    }

    region.next = region.prev = null;
  }

  fn push<T>(T mut * mut &head, T mut *node) -> void
  {
    while (true)
    {
      node.next = std::volatile_load(&head);

      if (std::atomic_cmpxchg_weak(&head, node.next, node))
        break;
    }
  }

  fn pop<T>(T mut * mut &head) -> T mut *
  {
    var node = head;

    if (node)
      head = node.next;

    return node;
  }

  fn grow_regions_freelist(heap mut &heap) -> void
  {
    var memory = mem_alloc(2*PAGE_SIZE);

    if (memory.errno != 0)
      return;

    var prev = &heap.firstfree;
    for (var addr = cast<uintptr>(memory.addr); addr + sizeof<region> <= cast<uintptr>(memory.addr) + memory.size; addr += sizeof<region>)
    {
      *prev = cast<region mut *>(addr);
      prev = &prev.next;
    }
  }

  fn new_region(heap mut &heap, mem_result allocation, usize klass) -> region mut *
  {
    if (!heap.firstfree)
      grow_regions_freelist(&mut heap);

    var region = pop(&mut heap.firstfree);

    if (!region)
      return null;

    region.size = allocation.size;
    region.addr = allocation.addr;
    region.firstfree = null;
    region.klass = klass;

    return region;
  }

  fn reap(heap mut &heap, entry mut * mut &pending) -> void
  {
    for (var entry = std::atomic_xchg(&pending, null); entry; )
    {
      var next = entry.next;
      var region = entry.region;

      push(&mut region.firstfree, entry);

      if (!entry.next)
      {
        var sc = region.klass;

        dequeue(&mut heap.filled, region);
        enqueue(&mut heap.active[sc], region);
      }

      entry = next;
    }
  }

  struct allocation
  {
    usize size;
    void mut *addr;

    allocation() = default;
    allocation(allocation&) = default;
    ~allocation() = default;
  }

  fn allocate(heap mut &heap, usize size, usize alignment) -> allocation
  {
    var result = allocation();

    var region = null<region mut *>();
    var entry = null<entry mut *>();

    var sz = size;

    if (alignment > 16)
      sz += alignment;

    var sc = size_to_klass(sz);

    switch (sc)
    {
      case 0 ..= 47:
        sz = size_of_klass(sc);

        heap.lock.lock();

        reap(&mut heap, &mut heap.pending[sc]);

        if (region = heap.active[sc])
        {
          entry = pop(&mut region.firstfree);

          if (!region.firstfree)
          {
            dequeue(&mut heap.active[sc], region);
            enqueue(&mut heap.filled, region);
          }
        }

        heap.lock.unlock();

        if (!entry)
        {
          var memory = mem_alloc(std::align_up(8*sz, PAGE_SIZE));

          if (memory.errno != 0)
            return result;

          cast<header mut *>(memory.addr).secret = SECRET;

          heap.lock.lock();

          if (region = heap.new_region(memory, sc); !region)
          {
            heap.lock.unlock();
            mem_free(memory.addr, memory.size);

            return result;
          }

          var prev = &region.firstfree;
          for (var addr = cast<uintptr>(memory.addr) + sizeof<header>; addr + sz <= cast<uintptr>(memory.addr) + memory.size; addr += sz)
          {
            *prev = cast<entry mut *>(addr);
            prev.region = region;
            prev = &prev.next;
          }

          entry = pop(&mut region.firstfree);

          enqueue(&mut heap.active[sc], region);

          heap.lock.unlock();
        }

      case 63:
        var memory = mem_alloc(size + sizeof<header> + sizeof<prefix>);

        if (memory.errno != 0)
          return result;

        sz = memory.size - sizeof<header>;

        cast<header mut *>(memory.addr).secret = SECRET;

        heap.lock.lock();

        if (region = heap.new_region(memory, 63); !region)
        {
          heap.lock.unlock();
          mem_free(memory.addr, memory.size);

          return result;
        }

        entry = cast<entry mut *>(cast<uintptr>(region.addr) + sizeof<header>);

        enqueue(&mut heap.filled, region);

        heap.lock.unlock();

      else:
        std::panic("unhandled klass");
    }

    result.addr = cast<void mut *>(std::align_up(cast<uintptr>(entry) + sizeof<prefix>, alignment));
    result.size = sz - (cast<uintptr>(result.addr) - cast<uintptr>(entry));

    (cast<prefix mut *>(result.addr) - 1).region = region;

    return result;
  }

  fn siphon(heap mut &heap, usize size) -> entry mut *
  {
    var region = null<region mut *>();
    var entries = null<entry mut *>();

    var sc = size_to_klass(size);

    switch (sc)
    {
      case 0 ..= 47:

        heap.lock.lock();

        reap(&mut heap, &mut heap.pending[sc]);

        if (region = heap.active[sc])
        {
          std::swap(&mut entries, &mut region.firstfree);

          dequeue(&mut heap.active[sc], region);
          enqueue(&mut heap.filled, region);
        }

        heap.lock.unlock();

      else:
        std::panic("unhandled klass");
    }

    return entries;
  }

  fn free(heap mut &heap, void *addr) -> void
  {
    var region = (cast<prefix mut *>(addr) - 1).region;

    std::assert(region, "bad free address");
    std::assert(region.addr, "bad free address");
    std::assert(*cast<uintptr*>(region.addr) == SECRET, "heap corruption");

    switch (region.klass)
    {
      case 0 ..= 47:
        var sc = region.klass;
        var sz = size_of_klass(region.klass);
        var slot = (cast<uintptr>(addr) - (cast<uintptr>(region.addr) + sizeof<header>)) / sz;
        var entry = cast<entry mut *>(cast<uintptr>(region.addr) + sizeof<header> + slot * sz);

        push(&mut heap.pending[sc], entry);

      case 63:
        mem_free(region.addr, region.size);

        heap.lock.lock();

        dequeue(&mut heap.filled, region);
        push(&mut heap.firstfree, region);

        heap.lock.unlock();

      else:
        std::panic("heap corruption");
    }
  }

  fn reap(heap mut &heap) -> void
  {
    heap.lock.lock();

    for (var sc = 0; sc < 48; ++sc)
    {
      reap(&mut heap, &mut heap.pending[sc]);
    }

    heap.lock.unlock();
  }

  fn trim(heap mut &heap) -> void
  {
    heap.lock.lock();

    for (var sc = 0; sc < 48; ++sc)
    {
      reap(&mut heap, &mut heap.pending[sc]);

      for (var region = heap.active[sc]; region; )
      {
        var head = heap.active[sc];
        var next = region.next;

        var cnt = 0;
        for (var free = region.firstfree; free; free = free.next)
          cnt += 1;

        if (cnt == (region.size - sizeof<heap::header>) / heap::size_of_klass(region.klass))
        {
          mem_free(region.addr, region.size);

          dequeue(&mut heap.active[sc], region);
          push(&mut heap.firstfree, region);
        }

        if (next == head)
          break;

        region = next;
      }
    }

    heap.lock.unlock();
  }

  fn instance() -> heap mut &
  {
    static instance = #heap();

    return &instance;
  }

  heap() = default;
  heap(#heap&) = default;
  ~heap() = default;
}

fn dump(heap &&heap) -> void
{
  heap.lock.lock();

  var available = 0;
  for (var free = heap.firstfree; free; free = free.next)
    available += 1;

  std::print("available regions: \n  ", available);

  std::print("filled regions:");

  for (var region = heap.filled; region; )
  {
    if (region.klass < 63)
      std::print("  ", region, ": ", region.addr, " [", region.size, "], ", (region.size - sizeof<heap::header>) / heap::size_of_klass(region.klass), " [x", heap::size_of_klass(region.klass), "] used");
    else
      std::print("  ", region, ": ", region.addr, " [", region.size, "]");

    region = region.next;

    if (region == heap.filled)
      break;
  }

  if (!heap.filled)
    std::print("  <none>");

  std::print("active regions:");

  var active = false;

  for (var sc = 0; sc < 48; ++sc)
  {
    if (heap.active[sc])
      active = true;

    for (var region = heap.active[sc]; region; )
    {
      var cnt = 0;
      for (var free = region.firstfree; free; free = free.next)
        cnt += 1;

      var used = (region.size - sizeof<heap::header>) / heap::size_of_klass(region.klass) - cnt;

      if (used == 0)
        std::print("  ", region, ": ", region.addr, " [", region.size, "], ", cnt, " [x", heap::size_of_klass(region.klass), "] free");
      else
        std::print("  ", region, ": ", region.addr, " [", region.size, "], ", cnt, " [x", heap::size_of_klass(region.klass), "] free, ", used, " used");

      region = region.next;

      if (region == heap.active[sc])
        break;
    }
  }

  if (!active)
    std::print("  <none>");

  std::print("pending free:");

  var pending = false;

  for (var sc = 0; sc < 48; ++sc)
  {
    if (heap.pending[sc])
      pending = true;

    for (var entry = heap.pending[sc]; entry; entry = entry.next)
      std::print("  ", entry.region, ": ", entry, " [", heap::size_of_klass(entry.region.klass), "]");
  }

  if (!pending)
    std::print("  <none>");

  heap.lock.unlock();
}

struct tcache
{
  const N = 8;

  std::spin_lock[N] locks;
  heap::entry mut *[40][N] entries;

  fn push<T>(T mut * mut &head, T mut *node) -> void
  {
    node.next = head;

    head = node;
  }

  fn pop<T>(T mut * mut &head) -> T mut *
  {
    var node = head;

    if (node)
      head = node.next;

    return node;
  }

  fn get(tcache mut &tcache, usize size, usize alignment) -> heap::allocation
  {
    var result = heap::allocation();

    if (alignment > 16)
      return result;

    var sc = heap::size_to_klass(size);

    if (sc >= 40)
      return result;

    for (var i = 0; i < N; ++i)
    {
      static thread_local n = #usize(0);

      if (!tcache.locks[n].try_lock())
      {
        n = (n + 1) % N;

        continue;
      }

      if (!tcache.entries[n][sc])
      {
        tcache.entries[n][sc] = heap::siphon(&mut heap::instance, size);
      }

      if (tcache.entries[n][sc])
      {
        result.addr = &pop(&mut tcache.entries[n][sc]).next;
        result.size = heap::size_of_klass(sc) - sizeof<heap::prefix>;
      }

      tcache.locks[n].unlock();

      break;
    }

    return result;
  }

  fn reap(tcache mut &tcache) -> void
  {
    for (var n = 0; n < N; ++n)
    {
      tcache.locks[n].lock();

      for (var sc = 0; sc < 40; ++sc)
      {
        while (tcache.entries[n][sc])
          heap::free(&mut heap::instance, &pop(&mut tcache.entries[n][sc]).next);
      }

      tcache.locks[n].unlock();
    }
  }

  fn instance() -> tcache mut &
  {
    static instance = #tcache();

    return &instance;
  }

  tcache() = default;
  tcache(#tcache&) = default;
  ~tcache() = default;
}

pub fn allocate(usize size, usize alignment) -> heap::allocation
{
  if (var allocation = tcache::get(&mut tcache::instance, size, alignment); allocation.addr)
    return allocation;

  return heap::allocate(&mut heap::instance, size, alignment);
}

pub fn free(void *addr) -> void
{
  heap::free(&mut heap::instance, addr);
}

pub fn reap() -> void
{
  heap::reap(&mut heap::instance);
}

pub fn trim() -> void
{
  heap::trim(&mut heap::instance);
}

pub fn dump() -> void
{
  dump(heap::instance);
}
