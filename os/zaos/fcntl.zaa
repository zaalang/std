//
// fcntl
//

import std.stdlib;
import std.atomic;
import os.zaos.errno : *;

pub using uid_t = u32;
pub using gid_t = u32;
pub using mode_t = u32;
pub using off_t = u64;
pub using time_t = i64;
pub using dev_t = uintptr;
pub using ino_t = uintptr;

pub const O_RDONLY = 0x1;
pub const O_WRONLY = 0x2;
pub const O_RDWR = 0x3;

pub const O_CREAT = 0o100;
pub const O_EXCL = 0o200;
pub const O_TRUNC = 0o1000;
pub const O_APPEND = 0o2000;
pub const O_SYMLINK = 0o100000;
pub const O_DIRECTORY = 0o200000;
pub const O_NOFOLLOW = 0o400000;
pub const O_FILESYSTEM = 0o1000000;

pub const S_IUMSK = 0o7777;  // user settable bits

pub const S_IRWXU = 0o700;   // read, write, execute: owner
pub const S_IRUSR = 0o400;   // read permission: owner
pub const S_IWUSR = 0o200;   // write permission: owner
pub const S_IXUSR = 0o100;   // execute permission: owner
pub const S_IRWXG = 0o070;   // read, write, execute: group
pub const S_IRGRP = 0o040;   // read permission: group
pub const S_IWGRP = 0o020;   // write permission: group
pub const S_IXGRP = 0o010;   // execute permission: group
pub const S_IRWXO = 0o007;   // read, write, execute: other
pub const S_IROTH = 0o004;   // read permission: other
pub const S_IWOTH = 0o002;   // write permission: other
pub const S_IXOTH = 0o001;   // execute permission: other

pub const S_ISUID = 0o4000;  // set user id on execution
pub const S_ISGID = 0o2000;  // set group id on execution */
pub const S_ISVTX = 0o1000;  // sticky bit

pub const S_IFMT = 0xf000;   // type of file
pub const S_IFDATA = 0xb000; // socket dgram
pub const S_IFSOCK = 0xc000; // socket stream
pub const S_IFLNK = 0xa000;  // symbolic link
pub const S_IFREG = 0x8000;  // regular
pub const S_IFBLK = 0x6000;  // block device
pub const S_IFDIR = 0x4000;  // directory
pub const S_IFCHR = 0x2000;  // character device
pub const S_IFIFO = 0x1000;  // fifo

pub const N_ACCESS = 0x1;
pub const N_ATTRIB = 0x2;
pub const N_CLOSE_WRITE = 0x4;
pub const N_CLOSE_NOWRITE = 0x8;
pub const N_MKDIR = 0x10;
pub const N_CREATE = 0x20;
pub const N_UNLINK = 0x40;
pub const N_MODIFY = 0x100;
pub const N_MOVED = 0x400;
pub const N_RENAME = 0x1000;
pub const N_OPEN = 0x2000;
pub const N_ALL = 0xffff;

pub const STDIN_FILENO = 0;
pub const STDOUT_FILENO = 1;
pub const STDERR_FILENO = 2;
pub const STDROOT_FILENO = 4;
pub const STDCWD_FILENO = 5;

pub enum filetype
{
  unknown,
  block_device,
  character_device,
  directory,
  regular,
  socket_dgram,
  socket_stream,
  symlink,
}

pub enum stats
{
  pub const uid = 0x01;
  pub const gid = 0x02;
  pub const mode = 0x04;
  pub const size = 0x08;
  pub const mtime = 0x10;
  pub const ctime = 0x20;
  pub const btime = 0x40;
  pub const inode = 0x100;
  pub const device = 0x200;
}

pub struct stat
{
  pub uid_t uid,
  pub gid_t gid,
  pub mode_t mode,

  pub off_t size,

  pub time_t mtime,
  pub time_t ctime,
  pub time_t btime,

  pub ino_t inode,
  pub dev_t device,

  pub stat() = default;
  pub stat(stat&) = default;
  pub fn =(stat mut &, stat &) -> stat mut & = default;
  pub ~stat() = default;
}

pub fn type(stat &stat) -> filetype
{
  switch (stat.mode & S_IFMT)
  {
    case S_IFREG:
      return filetype::regular;

    case S_IFBLK:
      return filetype::block_device;

    case S_IFDIR:
      return filetype::directory;

    case S_IFCHR:
      return filetype::character_device;

    case S_IFLNK:
      return filetype::symlink;

    case S_IFDATA:
      return filetype::socket_dgram;

    case S_IFSOCK:
      return filetype::socket_stream;
  }

  return filetype::unknown;
}

pub struct dirent
{
  pub u32 rec_len;
  pub u16 file_type;
  pub u16 name_len;
  pub u8[0] file_name;

  pub fn name(this &) -> std::string_view
  {
    return std::string_view(this.file_name.data, cast<usize>(this.name_len));
  }

  pub fn type(this &) -> filetype
  {
    return cast<filetype>(this.file_type);
  }
}

pub const POLLIN = 0x001;
pub const POLLOUT = 0x004;

pub const POLLFD = 0x1;
pub const POLLTHREAD = 0x2;

pub struct pollevt
{
  pub i32 id;
  pub u16 type;
  pub u16 mask;
  pub uintptr user_data;

  pub pollevt(i32 id, u16 type, u16 mask, uintptr user_data)
    : id(id), type(type), mask(mask), user_data(user_data)
  {
  }

  pub pollevt() = default;
  pub pollevt(pollevt&) = default;
  pub fn =(pollevt mut &, pollevt &) -> pollevt mut & = default;
  pub ~pollevt() = default;
}

pub struct watchevt
{
  pub u32 len;
  pub u32 pad;
  pub u64 mask;
  pub uintptr user_data;

  pub struct info
  {
    pub const id = 1;
    pub const dir = 2;
    pub const name = 3;

    pub u16 type;
    pub u16 len;
  }

  pub struct id_info : pub info
  {
    pub uintptr id;
  }

  pub struct dir_info : pub info
  {
    pub uintptr id;
  }

  pub struct name_info : pub info
  {
    pub u8[0] file_name;

    pub fn name(this &) -> std::string_view
    {
      return std::string_view(this.file_name.data, cast<usize>(this.len - sizeof<info>));
    }
  }
}

pub struct string
{
  u8 *data;
  usize len;

  pub string(u8 *data, usize len)
    : len(len), data(data)
  {
  }

  pub string(typeof("") &str)
    : len(str.len), data(str.data)
  {
  }

  pub string(string&) = default;
  pub ~string() = default;
}

pub struct msg
{
  pub u8 mut *bytes;
  pub usize nbytes;
  pub i32 mut *fds;
  pub usize nfds;

  pub msg() = default;
  pub msg(msg&) = default;
  pub fn =(msg mut &, msg &) -> msg mut & = default;
  pub ~msg() = default;
}

pub struct cmsg
{
  pub u8 *bytes;
  pub usize nbytes;
  pub i32 *fds;
  pub usize nfds;

  pub cmsg() = default;
  pub cmsg(cmsg&) = default;
  pub fn =(cmsg mut &, cmsg &) -> cmsg mut & = default;
  pub ~cmsg() = default;
}

pub enum ioring_ops
{
  pub const open = 0x01;
  pub const stat = 0x02;
  pub const read = 0x03;
  pub const write = 0x04;
  pub const ioctl = 0x05;
  pub const close = 0x06;
  pub const select = 0x07;
  pub const dup = 0x08;
  pub const dup2 = 0x09;
  pub const mkdir = 0x0a;
  pub const rename = 0x0b;
  pub const link = 0x0c;
  pub const symlink = 0x0d;
  pub const chstat = 0x0e;
  pub const unlink = 0x0f;
  pub const poll_create = 0x10;
  pub const poll_add = 0x11;
  pub const poll_modify = 0x12;
  pub const poll_remove = 0x13;
  pub const poll_wait = 0x14;
  pub const notify_create = 0x15;
  pub const notify_add = 0x16;
  pub const notify_modify = 0x17;
  pub const notify_remove = 0x18;
  pub const event_create = 0x19;
  pub const buffer_create = 0x1a;
  pub const channel_create = 0x1b;
  pub const channel_read = 0x1c;
  pub const channel_write = 0x1d;
  pub const channel_call = 0x1e;
}

pub enum ioring_flags
{
  pub const fin = 0x1;
}

pub struct ioring_header
{
  pub u32 sq_head;
  pub u32 sq_tail;
  pub u32 sq_mask;
  pub u32 sq_offset;

  pub u32 cq_head;
  pub u32 cq_tail;
  pub u32 cq_mask;
  pub u32 cq_offset;

  u8[32] reserved;
}

pub struct ioring_sqe
{
  pub u8 op;
  pub u8 flags;
  pub u16 reserved1;
  pub u32 reserved2;
  pub uintptr[6] args;
  pub uintptr user_data;
}

pub struct ioring_cqe
{
  pub u32 flags;
  pub i32 result;
  pub uintptr user_data;
}

pub struct ioring
{
  pub i32 fd;
  pub ioring_header mut *header;

  pub ioring() = default;
  pub ioring(ioring&) = default;
  pub fn =(ioring mut &, ioring &) -> ioring mut & = default;
  pub ~ioring() = default;
}

#[weak]
extern fn __vdso_ioring_setup(void *buffer, usize bufferlen, u64 flags) -> i32;

#[weak]
extern fn __vdso_ioring_enter(i32 fd, u32 to_submit, u32 min_complete, u64 flags) -> i32;

#[weak]
extern fn __vdso_ioring_destroy(i32 fd) -> i32;

pub fn ioring_setup(void *buffer, usize bufferlen, u64 flags) -> i32
{
  return __vdso_ioring_setup(buffer, bufferlen, flags);
}

pub fn ioring_enter(i32 fd, u32 to_submit, u32 min_complete, u64 flags) -> i32
{
  return __vdso_ioring_enter(fd, to_submit, min_complete, flags);
}

pub fn ioring_destroy(i32 fd) -> i32
{
  return __vdso_ioring_destroy(fd);
}

pub fn ioring_get_sqe(ioring mut &ring) -> ioring_sqe mut *
{
  var tail = ring.header.sq_tail;
  var index = tail & ring.header.sq_mask;
  var next = std::add_with_carry(tail, 1).0;

  if (std::sub_with_borrow(next, std::volatile_load(&ring.header.sq_head)).0 > ring.header.sq_mask + 1)
    return null;

  return cast<ioring_sqe mut *>(cast<uintptr>(ring.header) + cast<usize>(ring.header.sq_offset + index * sizeof<ioring_sqe>));
}

pub fn ioring_advance_sqe(ioring mut &ring) -> void
{
  var tail = ring.header.sq_tail;
  var next = std::add_with_carry(tail, 1).0;

  std::atomic_store(&ring.header.sq_tail, next);
}

pub fn ioring_submit_sqe(ioring mut &ring) -> i32
{
  var tail = ring.header.sq_tail;
  var next = std::add_with_carry(tail, 1).0;

  std::atomic_store(&ring.header.sq_tail, next);

  return __vdso_ioring_enter(ring.fd, 1, 0, 0);
}

pub fn ioring_get_cqe(ioring mut &ring) -> ioring_cqe *
{
  var head = ring.header.cq_head;
  var index = head & ring.header.cq_mask;

  if (head == std::volatile_load(&ring.header.cq_tail))
    return null;

  std::atomic_thread_fence(std::memory_order::acquire);

  return cast<ioring_cqe*>(cast<uintptr>(ring.header) + cast<usize>(ring.header.cq_offset + index * sizeof<ioring_cqe>));
}

pub fn ioring_wait_cqe(ioring mut &ring) -> i32
{
  var head = ring.header.cq_head;
  var index = head & ring.header.sq_mask;

  if (head == std::volatile_load(&ring.header.sq_tail))
  {
    if (var rc = __vdso_ioring_enter(ring.fd, 0, 1, 0); rc < 0)
      return rc;
  }

  return 0;
}

pub fn ioring_advance_cqe(ioring mut &ring) -> void
{
  var head = ring.header.cq_head;
  var next = std::add_with_carry(head, 1).0;

  std::atomic_store(&ring.header.cq_head, next, std::memory_order::relaxed);
}

pub fn ioring_prep_sqe_open(ioring_sqe mut *sqe, i32 dir, string path, u64 flags, u32 mode) -> void
{
  sqe.op = ioring_ops::open;
  sqe.args[0] = cast<uintptr>(dir) << 32 | cast<uintptr>(path.len);
  sqe.args[1] = cast(path.data);
  sqe.args[2] = cast(flags);
  sqe.args[3] = cast(mode);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_stat(ioring_sqe mut *sqe, i32 fd, stat mut *statbuf, u64 flags) -> void
{
  sqe.op = ioring_ops::stat;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(statbuf);
  sqe.args[2] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_read(ioring_sqe mut *sqe, i32 fd, void mut *buffer, usize buflen) -> void
{
  sqe.op = ioring_ops::read;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(buffer);
  sqe.args[2] = cast(buflen);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_write(ioring_sqe mut *sqe, i32 fd, void *buffer, usize buflen) -> void
{
  sqe.op = ioring_ops::write;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(buffer);
  sqe.args[2] = cast(buflen);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_ioctl(ioring_sqe mut *sqe, i32 fd, u32 op, void mut *buffer, usize buflen) -> void
{
  sqe.op = ioring_ops::ioctl;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(op);
  sqe.args[2] = cast(buffer);
  sqe.args[3] = cast(buflen);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_close(ioring_sqe mut *sqe, i32 fd) -> void
{
  sqe.op = ioring_ops::close;
  sqe.args[0] = cast(fd);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_select(ioring_sqe mut *sqe, pollevt mut *evts, usize n, u64 timeout) -> void
{
  sqe.op = ioring_ops::select;
  sqe.args[0] = cast(evts);
  sqe.args[1] = cast(n);
  sqe.args[2] = cast(timeout);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_dup(ioring_sqe mut *sqe, i32 oldfd) -> void
{
  sqe.op = ioring_ops::dup;
  sqe.args[0] = cast(oldfd);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_dup2(ioring_sqe mut *sqe, i32 oldfd, i32 newfd) -> void
{
  sqe.op = ioring_ops::dup2;
  sqe.args[0] = cast(oldfd);
  sqe.args[1] = cast(newfd);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_mkdir(ioring_sqe mut *sqe, i32 dir, string path, u64 flags, u32 mode) -> void
{
  sqe.op = ioring_ops::mkdir;
  sqe.args[0] = cast<uintptr>(dir) << 32 | cast<uintptr>(path.len);
  sqe.args[1] = cast(path.data);
  sqe.args[2] = cast(flags);
  sqe.args[3] = cast(mode);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_rename(ioring_sqe mut *sqe, i32 olddir, string oldpath, i32 newdir, string newpath, u64 flags) -> void
{
  sqe.op = ioring_ops::rename;
  sqe.args[0] = cast<uintptr>(olddir) << 32 | cast<uintptr>(oldpath.len);
  sqe.args[1] = cast(oldpath.data);
  sqe.args[2] = cast<uintptr>(newdir) << 32 | cast<uintptr>(newpath.len);
  sqe.args[3] = cast(newpath.data);
  sqe.args[4] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_link(ioring_sqe mut *sqe, i32 olddir, string oldpath, i32 newdir, string newpath, u64 flags) -> void
{
  sqe.op = ioring_ops::link;
  sqe.args[0] = cast<uintptr>(olddir) << 32 | cast<uintptr>(oldpath.len);
  sqe.args[1] = cast(oldpath.data);
  sqe.args[2] = cast<uintptr>(newdir) << 32 | cast<uintptr>(newpath.len);
  sqe.args[3] = cast(newpath.data);
  sqe.args[4] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_symlink(ioring_sqe mut *sqe, i32 dir, string path, string target, u64 flags) -> void
{
  sqe.op = ioring_ops::symlink;
  sqe.args[0] = cast<uintptr>(dir) << 32 | cast<uintptr>(path.len);
  sqe.args[1] = cast(path.data);
  sqe.args[2] = cast(target.len);
  sqe.args[3] = cast(target.data);
  sqe.args[4] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_chstat(ioring_sqe mut *sqe, i32 fd, stat *statbuf, u64 flags) -> void
{
  sqe.op = ioring_ops::chstat;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(statbuf);
  sqe.args[2] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_unlink(ioring_sqe mut *sqe, i32 dir, string path, u64 flags) -> void
{
  sqe.op = ioring_ops::unlink;
  sqe.args[0] = cast<uintptr>(dir) << 32 | cast<uintptr>(path.len);
  sqe.args[1] = cast(path.data);
  sqe.args[2] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_poll_create(ioring_sqe mut *sqe, u64 flags) -> void
{
  sqe.op = ioring_ops::poll_create;
  sqe.args[0] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_poll_add(ioring_sqe mut *sqe, i32 fd, i32 id, u16 type, u16 mask, uintptr user_data, u64 flags) -> void
{
  sqe.op = ioring_ops::poll_add;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(id);
  sqe.args[2] = cast(type);
  sqe.args[3] = cast(mask);
  sqe.args[4] = cast(user_data);
  sqe.args[5] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_poll_remove(ioring_sqe mut *sqe, i32 fd, i32 id, u16 type) -> void
{
  sqe.op = ioring_ops::poll_remove;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(id);
  sqe.args[2] = cast(type);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_poll_wait(ioring_sqe mut *sqe, i32 fd, pollevt mut *evts, usize n, u64 timeout) -> void
{
  sqe.op = ioring_ops::poll_wait;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(evts);
  sqe.args[2] = cast(n);
  sqe.args[3] = cast(timeout);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_notify_create(ioring_sqe mut *sqe, u64 flags) -> void
{
  sqe.op = ioring_ops::notify_create;
  sqe.args[0] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_notify_add(ioring_sqe mut *sqe, i32 fd, i32 dir, string path, u64 mask, uintptr user_data, u64 flags) -> void
{
  sqe.op = ioring_ops::notify_add;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast<uintptr>(dir) << 32 | cast<uintptr>(path.len);
  sqe.args[2] = cast(path.data);
  sqe.args[3] = cast(mask);
  sqe.args[4] = cast(user_data);
  sqe.args[5] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_notify_remove(ioring_sqe mut *sqe, i32 fd, i32 dir, string path) -> void
{
  sqe.op = ioring_ops::notify_remove;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast<uintptr>(dir) << 32 | cast<uintptr>(path.len);
  sqe.args[2] = cast(path.data);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_event_create(ioring_sqe mut *sqe, u64 value, u64 maxvalue, u64 flags) -> void
{
  sqe.op = ioring_ops::event_create;
  sqe.args[0] = cast(value);
  sqe.args[1] = cast(maxvalue);
  sqe.args[2] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_buffer_create(ioring_sqe mut *sqe, i32[2] mut *fds, usize size, u64 flags) -> void
{
  sqe.op = ioring_ops::buffer_create;
  sqe.args[0] = cast(fds);
  sqe.args[1] = cast(size);
  sqe.args[2] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_channel_create(ioring_sqe mut *sqe, i32[2] mut *fds, u64 flags) -> void
{
  sqe.op = ioring_ops::channel_create;
  sqe.args[0] = cast(fds);
  sqe.args[1] = cast(flags);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_channel_read(ioring_sqe mut *sqe, i32 fd, i32 mut *sid, msg mut *buffer, usize mut *outbytes, usize mut *outfds) -> void
{
  sqe.op = ioring_ops::channel_read;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(sid);
  sqe.args[2] = cast(buffer);
  sqe.args[3] = cast(outbytes);
  sqe.args[4] = cast(outfds);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_channel_write(ioring_sqe mut *sqe, i32 fd, i32 sid, cmsg *msg) -> void
{
  sqe.op = ioring_ops::channel_write;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(sid);
  sqe.args[2] = cast(msg);
  sqe.flags = ioring_flags::fin;
}

pub fn ioring_prep_sqe_channel_call(ioring_sqe mut *sqe, i32 fd, cmsg mut *msg, msg mut *buffer, usize mut *outbytes, usize mut *outfds) -> void
{
  sqe.op = ioring_ops::channel_call;
  sqe.args[0] = cast(fd);
  sqe.args[1] = cast(msg);
  sqe.args[2] = cast(buffer);
  sqe.args[3] = cast(outbytes);
  sqe.args[4] = cast(outfds);
  sqe.flags = ioring_flags::fin;
}

pub fn open(ioring mut &ring, i32 dir, string path, u64 flags, u32 mode) -> i32
{
  if (dir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_open(sqe, dir, path, flags, mode);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn open(ioring mut &ring, string path, u64 flags, u32 mode) -> i32
{
  var dir = STDCWD_FILENO;

  if (path.len > 0 && *path.data == cast('/'))
    dir = STDROOT_FILENO;

  return open(&mut ring, dir, path, flags, mode);
}

pub fn stat(ioring mut &ring, i32 fd, stat mut *statbuf, u64 flags) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_stat(sqe, fd, statbuf, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn read(ioring mut &ring, i32 fd, void mut *buffer, usize buflen) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_read(sqe, fd, buffer, buflen);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn write(ioring mut &ring, i32 fd, void *buffer, usize buflen) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_write(sqe, fd, buffer, buflen);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn ioctl(ioring mut &ring, i32 fd, u32 op, void mut *buffer, usize buflen) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_ioctl(sqe, fd, op, buffer, buflen);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn close(ioring mut &ring, i32 fd) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_close(sqe, fd);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn select(ioring mut &ring, pollevt mut *evts, usize n, u64 timeout) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_select(sqe, evts, n, timeout);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn dup(ioring mut &ring, i32 oldfd) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_dup(sqe, oldfd);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn dup2(ioring mut &ring, i32 oldfd, i32 newfd) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_dup2(sqe, oldfd, newfd);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn mkdir(ioring mut &ring, i32 dir, string path, u64 flags, u32 mode) -> i32
{
  if (dir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_mkdir(sqe, dir, path, flags, mode);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn mkdir(ioring mut &ring, string path, u64 flags, u32 mode) -> i32
{
  var dir = STDCWD_FILENO;

  if (path.len > 0 && *path.data == cast('/'))
    dir = STDROOT_FILENO;

  return mkdir(&mut ring, dir, path, flags, mode);
}

pub fn rename(ioring mut &ring, i32 olddir, string oldpath, i32 newdir, string newpath, u64 flags) -> i32
{
  if (olddir < 0 || newdir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_rename(sqe, olddir, oldpath, newdir, newpath, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn rename(ioring mut &ring, string oldpath, string newpath, u64 flags) -> i32
{
  var olddir = STDCWD_FILENO;

  if (oldpath.len > 0 && *oldpath.data == cast('/'))
    olddir = STDROOT_FILENO;

  var newdir = STDCWD_FILENO;

  if (newpath.len > 0 && *newpath.data == cast('/'))
    newdir = STDROOT_FILENO;

  return rename(&mut ring, olddir, oldpath, newdir, newpath, flags);
}

pub fn link(ioring mut &ring, i32 olddir, string oldpath, i32 newdir, string newpath, u64 flags) -> i32
{
  if (olddir < 0 || newdir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_link(sqe, olddir, oldpath, newdir, newpath, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn link(ioring mut &ring, string oldpath, string newpath, u64 flags) -> i32
{
  var olddir = STDCWD_FILENO;

  if (oldpath.len > 0 && *oldpath.data == cast('/'))
    olddir = STDROOT_FILENO;

  var newdir = STDCWD_FILENO;

  if (newpath.len > 0 && *newpath.data == cast('/'))
    newdir = STDROOT_FILENO;

  return link(&mut ring, olddir, oldpath, newdir, newpath, flags);
}

pub fn symlink(ioring mut &ring, i32 dir, string path, string target, u64 flags) -> i32
{
  if (dir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_symlink(sqe, dir, path, target, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn symlink(ioring mut &ring, string path, string target, u64 flags) -> i32
{
  var dir = STDCWD_FILENO;

  if (path.len > 0 && *path.data == cast('/'))
    dir = STDROOT_FILENO;

  return symlink(&mut ring, dir, path, target, flags);
}

pub fn chstat(ioring mut &ring, i32 fd, stat *statbuf, u64 flags) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_chstat(sqe, fd, statbuf, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn unlink(ioring mut &ring, i32 dir, string path, u64 flags) -> i32
{
  if (dir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_unlink(sqe, dir, path, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn unlink(ioring mut &ring, string path, u64 flags) -> i32
{
  var dir = STDCWD_FILENO;

  if (path.len > 0 && *path.data == cast('/'))
    dir = STDROOT_FILENO;

  return unlink(&mut ring, dir, path, flags);
}

pub fn poll_create(ioring mut &ring, u64 flags) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_poll_create(sqe, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn poll_add(ioring mut &ring, i32 fd, i32 id, u16 type, u16 mask, uintptr user_data, u64 flags) -> i32
{
  if (fd < 0)
    return EINVAL;

  if (id < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_poll_add(sqe, fd, id, type, mask, user_data, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn poll_remove(ioring mut &ring, i32 fd, i32 id, u16 type) -> i32
{
  if (fd < 0)
    return EINVAL;

  if (id < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_poll_remove(sqe, fd, id, type);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn poll_wait(ioring mut &ring, i32 fd, pollevt mut *evts, usize n, u64 timeout) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_poll_wait(sqe, fd, evts, n, timeout);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn notify_create(ioring mut &ring, u64 flags) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_notify_create(sqe, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn notify_add(ioring mut &ring, i32 fd, i32 dir, string path, u64 mask, uintptr user_data, u64 flags) -> i32
{
  if (fd < 0)
    return EINVAL;

  if (dir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_notify_add(sqe, fd, dir, path, mask, user_data, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn notify_remove(ioring mut &ring, i32 fd, i32 dir, string path, u64 mask) -> i32
{
  if (fd < 0)
    return EINVAL;

  if (dir < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_notify_remove(sqe, fd, dir, path, mask);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn event_create(ioring mut &ring, u64 value, u64 maxvalue, u64 flags) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_event_create(sqe, value, maxvalue, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn buffer_create(ioring mut &ring, i32[2] mut *fds, usize size, u64 flags) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_buffer_create(sqe, fds, size, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn channel_create(ioring mut &ring, i32[2] mut *fds, u64 flags) -> i32
{
  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_channel_create(sqe, fds, flags);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn channel_read(ioring mut &ring, i32 fd, i32 mut *sid, msg mut *buffer, usize mut *outbytes, usize mut *outfds) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_channel_read(sqe, fd, sid, buffer, outbytes, outfds);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn channel_write(ioring mut &ring, i32 fd, i32 sid, cmsg *msg) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_channel_write(sqe, fd, sid, msg);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}

pub fn channel_call(ioring mut &ring, i32 fd, cmsg mut *msg, msg mut *buffer, usize mut *outbytes, usize mut *outfds) -> i32
{
  if (fd < 0)
    return EINVAL;

  var sqe = ioring_get_sqe(&mut ring);
  ioring_prep_sqe_channel_call(sqe, fd, msg, buffer, outbytes, outfds);
  ioring_advance_sqe(&mut ring);

  if (var rc = __vdso_ioring_enter(ring.fd, 1, 1, 0); rc < 0)
    return rc;

  var cqe = ioring_get_cqe(&mut ring);
  var result = cqe.result;
  ioring_advance_cqe(&mut ring);

  return result;
}
